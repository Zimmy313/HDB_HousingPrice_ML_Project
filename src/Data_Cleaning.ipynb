{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Package and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1999 = pd.read_csv(\"../data/ResaleFlatPricesBasedonApprovalDate19901999.csv\")\n",
    "df_2012 = pd.read_csv(\"../data/ResaleFlatPricesBasedonApprovalDate2000Feb2012.csv\")\n",
    "df_2014 = pd.read_csv(\"../data/ResaleFlatPricesBasedonRegistrationDateFromMar2012toDec2014.csv\")\n",
    "df_2016 = pd.read_csv(\"../data/ResaleFlatPricesBasedonRegistrationDateFromJan2015toDec2016.csv\")\n",
    "df_2017 = pd.read_csv(\"../data/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "\n",
    "# checking for Na and duplicates\n",
    "def clean_dataset(df, dataset_name):\n",
    "    print(f\"Cleaning dataset: {dataset_name}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates_count = df.duplicated().sum()\n",
    "    print(f\"{dataset_name}: Number of duplicates: {duplicates_count}\")\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df_cleaned = df.drop_duplicates().copy()          \n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df_cleaned.isna().sum()\n",
    "    print(f\"{dataset_name}: Missing values per column:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# splitting categorical and numerical values:\n",
    "def split_categorical_numerical(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object'])\n",
    "    numerical_columns = df.select_dtypes(include=['number'])\n",
    "    return categorical_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and split each dataset, and save them with variable names\n",
    "\n",
    "# 1. Clean and split df_1999\n",
    "df_1999_cleaned = clean_dataset(df_1999, \"1999\")\n",
    "df_1999_col, df_1999_num = split_categorical_numerical(df_1999_cleaned)\n",
    "\n",
    "# 2. Clean and split df_2012\n",
    "df_2012_cleaned = clean_dataset(df_2012, \"2012\")\n",
    "df_2012_col, df_2012_num = split_categorical_numerical(df_2012_cleaned)\n",
    "\n",
    "# 3. Clean and split df_2014\n",
    "df_2014_cleaned = clean_dataset(df_2014, \"2014\")\n",
    "df_2014_col, df_2014_num = split_categorical_numerical(df_2014_cleaned)\n",
    "\n",
    "# 4. Clean and split df_2016\n",
    "df_2016_cleaned = clean_dataset(df_2016, \"2016\")\n",
    "df_2016_col, df_2016_num = split_categorical_numerical(df_2016_cleaned)\n",
    "\n",
    "# 5. Clean and split df_2017\n",
    "df_2017_cleaned = clean_dataset(df_2017, \"2017\")\n",
    "df_2017_col, df_2017_num = split_categorical_numerical(df_2017_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a heat map of the numerical values\n",
    "numerical_combined = pd.concat([df_1999_num, df_2012_num, df_2014_num, df_2016_num, df_2017_num])\n",
    "correlation_matrix = numerical_combined.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Combined Numerical Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_combined.columns\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(numerical_combined[column], bins=30, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalisation/Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14px;\"> `clean_flat_model` convert all `str` to uppercase and strip whitespaces left and right </span>\n",
    "\n",
    "<span style=\"font-size: 14px;\">  `convert_remaining_lease` convert the types(`timedelta`, `int` and `str`) into `float` type </span>\n",
    "\n",
    "<span style=\"font-size: 14px;\">  `convert_month_to_datetime` convert `month` column from `str` to `datetime` </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_flat_model(df):\n",
    "    df['flat_model'] = df['flat_model'].str.strip().str.upper()\n",
    "    return df \n",
    "\n",
    "\n",
    "def convert_remaining_lease(df):\n",
    "    # When input is a dataframe\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for index, row in df.iterrows():\n",
    "            # Convert remaining_lease that are string to float\n",
    "            if isinstance(row['remaining_lease'], str):\n",
    "                remaining_lease_str = row[\"remaining_lease\"].lower()\n",
    "                years = 0\n",
    "                months = 0\n",
    "                \n",
    "                if 'years' in remaining_lease_str:\n",
    "                    years = int(remaining_lease_str.split('years')[0].strip())\n",
    "                if 'months' in remaining_lease_str:\n",
    "                    months = int(remaining_lease_str.split('months')[0].split()[-1].strip())\n",
    "                df.loc[index, 'remaining_lease'] = years + months / 12\n",
    "            \n",
    "            # convert remaining_lease that are timedelta to float, needed for the function(filling of remaining_lease)\n",
    "            elif isinstance(row['remaining_lease'], pd.Timedelta):\n",
    "                df.loc[index, 'remaining_lease'] = float(row['remaining_lease'].days / 365)\n",
    "\n",
    "            # convert remaining_lease that are int to float\n",
    "            elif isinstance(row['remaining_lease'], int):\n",
    "                df.loc[index, 'remaining_lease'] = float(row['remaining_lease'])\n",
    "        return df\n",
    "    \n",
    "    # When input is single value\n",
    "    # Convert remaining_lease that are string to float\n",
    "    elif isinstance(df, str):\n",
    "        remaining_lease_str = df.lower()\n",
    "        years = 0\n",
    "        months = 0\n",
    "        \n",
    "        if 'years' in remaining_lease_str:\n",
    "            years = int(remaining_lease_str.split('years')[0].strip())\n",
    "        if 'months' in remaining_lease_str:\n",
    "            months = int(remaining_lease_str.split('months')[0].split()[-1].strip())\n",
    "        return years + months / 12\n",
    "    \n",
    "    # convert remaining_lease that are timedelta to float, needed for code below(filling of remaining_lease)\n",
    "    elif isinstance(df, pd.Timedelta):\n",
    "        return float(df.days / 365)\n",
    "\n",
    "    # convert remaining_lease that are int to float\n",
    "    elif isinstance(df, int):\n",
    "        return float(df)\n",
    "\n",
    "    # if df is None or other type, return original value\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "def convert_month_to_datetime(df, column_name='month'):\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format='%Y-%m', errors='coerce')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14px;\"> `split_storey_range` add in the columns of `lower_storey` and `upper_storey` derived from  `storey_range` </span>\n",
    "\n",
    "<span style=\"font-size: 14px;\"> `split_month_column` add in the columns of `year` and `month_number` derived from `month`</span>\n",
    "\n",
    "<span style=\"font-size: 14px;\"> `add_max_storey` add in the column `max_storey` for each building (at the very least the highest storey recorded)</span>\n",
    "\n",
    "<span style=\"font-size: 14px;\">  `adjust_remaining_lease` fill up as many missing values in `remaining_lease` using information from buildings that have values in `remaining_lease`</span>\n",
    "\n",
    "<span style=\"font-size: 14px;\">  add price/square meter </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_storey_range(df):\n",
    "    \"\"\"\n",
    "    Splits the 'storey_range' column into 'lower_storey' and 'upper_storey'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing the 'storey_range' column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Modified DataFrame with 'lower_storey' and 'upper_storey' columns added.\n",
    "    \"\"\"\n",
    "    # Splitting the 'storey_range' column into 'lower_storey' and 'upper_storey'\n",
    "    df[['lower_storey', 'upper_storey']] = df['storey_range'].str.split(' TO ', expand=True)\n",
    "\n",
    "    # Convert lower_storey and upper_storey to numeric types\n",
    "    df['lower_storey'] = pd.to_numeric(df['lower_storey'], errors='coerce')\n",
    "    df['upper_storey'] = pd.to_numeric(df['upper_storey'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_month_column(df):\n",
    "    \"\"\"\n",
    "    Splits the 'month' column into 'year' and 'month_number'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing the 'month' column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Modified DataFrame with 'year' and 'month_number' columns added.\n",
    "    \"\"\"\n",
    "    # Splitting the 'month' column into 'year' and 'month_number'\n",
    "    df['year'] = pd.to_datetime(df['month']).dt.year\n",
    "    df['month_number'] = pd.to_datetime(df['month']).dt.month\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_max_storey(df):\n",
    "    \"\"\"\n",
    "    Adds a column 'max_storey' to the DataFrame based on the maximum upper_storey \n",
    "    for each unique combination of town, block, and street_name.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing 'town', 'block', 'street_name', and 'upper_storey'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Modified DataFrame with the new 'max_storey' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create max_storey column\n",
    "    df['max_storey'] = df.groupby(['town', 'block', 'street_name'])['upper_storey'].transform('max')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add price per square meter\n",
    "full_cleaned['price_per_sqm'] = full_cleaned['resale_price'] / full_cleaned['floor_area_sqm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver 2 with conversion of remaining_lease to numeric included\n",
    "def adjust_remaining_lease(df):\n",
    "    # Create a dictionary with keys as unique buildings and values initialized to None\n",
    "    unique_buildings = df[['town', 'block', 'street_name']].drop_duplicates().values.tolist()\n",
    "    building_dict = {(town, block, street_name): None for town, block, street_name in unique_buildings}\n",
    "\n",
    "    print(\"Successfully created building dictionary: \", len(building_dict))\n",
    "\n",
    "\n",
    "    # Convert month to datetime format just in case\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['month']):\n",
    "        df = convert_month_to_datetime(df)\n",
    "\n",
    "    # Sort the dataframe by month in descending order\n",
    "    df = df.sort_values(by='month', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Fill building_dict with lease end dates\n",
    "    # also convert remaining_lease to numeric value\n",
    "    for index, row in df.iterrows():\n",
    "        key = (row['town'], row['block'], row['street_name'])\n",
    "        if pd.isna(row['remaining_lease']):\n",
    "            continue\n",
    "\n",
    "        if building_dict[key] is not None:\n",
    "            df.loc[index, 'remaining_lease'] = convert_remaining_lease(row['remaining_lease'])\n",
    "            continue\n",
    "\n",
    "\n",
    "        if isinstance(row['remaining_lease'], str):\n",
    "            remaining_lease_str = row[\"remaining_lease\"].lower()\n",
    "            years = 0\n",
    "            months = 0\n",
    "            if 'years' in remaining_lease_str:\n",
    "                years = int(remaining_lease_str.split('years')[0].strip())\n",
    "            if 'months' in remaining_lease_str:\n",
    "                months = int(remaining_lease_str.split('months')[0].split()[-1].strip())\n",
    "            remaining_lease = pd.offsets.DateOffset(years=years, months=months)\n",
    "            lease_end_date = row['month'] + remaining_lease\n",
    "            df.loc[index, 'remaining_lease'] = years + months / 12\n",
    "        elif isinstance(row['remaining_lease'], (int, float)):\n",
    "            years = int(row['remaining_lease'])\n",
    "            months = int((row['remaining_lease'] - years) * 12) + 1\n",
    "            remaining_lease = pd.offsets.DateOffset(years=years, months=months)\n",
    "            lease_end_date = row['month'] + remaining_lease\n",
    "            if isinstance(row['remaining_lease'], int):\n",
    "                df.loc[index, 'remaining_lease'] = float(row['remaining_lease'])\n",
    "\n",
    "        building_dict[key] = lease_end_date\n",
    "\n",
    "    print(\"Successfully filled lease end date for each building\")\n",
    "\n",
    "    # Fill missing remaining_lease values\n",
    "    for index, row in df.iterrows():\n",
    "        key = (row['town'], row['block'], row['street_name'])\n",
    "        if building_dict[key] is None:\n",
    "            continue\n",
    "        if pd.isna(row['remaining_lease']):\n",
    "            remaining_lease = (building_dict[key] - row['month']).days / 365\n",
    "            df.loc[index, 'remaining_lease'] = float(remaining_lease)\n",
    "        elif 2015 <= row['month'].year <= 2016:\n",
    "            remaining_lease = (building_dict[key] - row['month']).days / 365\n",
    "            df.loc[index, 'remaining_lease'] = float(remaining_lease) \n",
    "\n",
    "    print(\"Successfully filled missing remaining lease for each building\")\n",
    "\n",
    "    # Sort df by month\n",
    "    df = df.sort_values(by='month', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14px;\"> `filter_building` takes in the input of (df,'town', 'block', 'street_name'), and return all the transaction related to that buildling </span>\n",
    "\n",
    "<span style=\"font-size: 14px;\"> `get_column_data_types` displays the total number of each type for each column </span>\n",
    "\n",
    "<span style=\"font-size: 14px;\"> take note that the value Nan is still considered a float type in python, but this function do not consider Nan as float but its seperate group </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_building(df, town, block, street_name):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for listings of a specific building.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing property listings.\n",
    "    town (str): The town of the building.\n",
    "    block (int): The block number of the building.\n",
    "    street_name (str): The street name of the building.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame containing listings for the specified building.\n",
    "    \"\"\"\n",
    "    filtered_df = df[(df['town'] == town) & \n",
    "                     (df['block'] == block) & \n",
    "                     (df['street_name'] == street_name)]\n",
    "    \n",
    "    num_rows = len(filtered_df)\n",
    "    print(f\"Total number of transactions for the building: {num_rows}\")\n",
    "    #print(filtered_df)\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def get_column_data_types(df):\n",
    "\n",
    "    # do take note that Nan is considered as a float type\n",
    "    if isinstance(df, pd.Series):\n",
    "        data_types = df.apply(lambda x: 'NaN' if pd.isna(x) else type(x))\n",
    "        data_types = data_types.value_counts()\n",
    "    else:\n",
    "        data_types = df.applymap(lambda x: 'NaN' if pd.isna(x) else type(x))\n",
    "        data_types = data_types.apply(lambda x: x.value_counts())\n",
    "    print(data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making of full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [\n",
    "    df_2017_cleaned,\n",
    "    df_2016_cleaned,\n",
    "    df_2014_cleaned,\n",
    "    df_2012_cleaned,\n",
    "    df_1999_cleaned\n",
    "]\n",
    "\n",
    "full_cleaned = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "full_cleaned = split_month_column(full_cleaned)\n",
    "full_cleaned = split_storey_range(full_cleaned)\n",
    "full_cleaned = add_max_storey(full_cleaned)\n",
    "full_cleaned = convert_month_to_datetime(full_cleaned)\n",
    "full_cleaned = clean_flat_model(full_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `remaining_lease` that have data is 226161 where 37129 is int and 189032 is str, and there is a total of 707463 missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_data_types(full_cleaned[\"remaining_lease\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Information on finding `remaining_lease` for pre-Jan 2015\n",
    "\n",
    "`remaining_lease` from Jan 2015 to Dec 2016 are in `int`\n",
    "\n",
    "While `remaining_lease` from Jan 2017 onwards are in `str` and are in the format of \"## years ## months\" or \" ## years\"\n",
    "\n",
    "Meanwhile, `remaining_lease` in pre-Jan 2015 are not available/Nan\n",
    "\n",
    "Thus, this function `adjust_remaining_lease` aims to figure out the `remaining_lease` in the data of pre-Jan 2015 by finding out what is the lease end date using data from Jan 2015 onwards\n",
    "\n",
    "The function sort the data from latest to earliest date of transaction this is because the latest transaction `remaining_lease` can derive number of years and months left while 2015 to 2016 data only derive number of years left, so sorting in descending order would ensure the dictionary in the function will be filled with the most updated data\n",
    "\n",
    "##### Additional information:\n",
    "\n",
    "For buildings where `remaining_lease` are still Nan after running the function, it means those building do not have transactions post-Jan 2015\n",
    "\n",
    "Likely those buildings were scheduled for en-bloc and are either already demolished or preparing to be demolished, hence the lack of transactions post-Jan 2015\n",
    "\n",
    "For more information, google search \"completed SERS projects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned = adjust_remaining_lease(full_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After filling missing values of remaining_lease number of missing data is cut down from 707463 to 18994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>    914630\n",
      "NaN                 18994\n",
      "Name: remaining_lease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_column_data_types(full_cleaned[\"remaining_lease\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned\n",
    "get_column_data_types(full_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the maximum storey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of the maximum storey\n",
    "lst_of_max_storey = full_cleaned.groupby(['town', 'block', 'street_name'], as_index=False)['max_storey'].max()\n",
    "# Plot the histogram of max_storey\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lst_of_max_storey['max_storey'], bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Maximum Storey by Building')\n",
    "plt.xlabel('Maximum Storey')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of unique buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique buildings: 9846\n"
     ]
    }
   ],
   "source": [
    "# Count unique buildings based on town, block, and street_name\n",
    "unique_buildings_count = full_cleaned.groupby(['town', 'block', 'street_name']).size().count()\n",
    "\n",
    "# Display the total number of unique buildings\n",
    "print(f\"Total number of unique buildings: {unique_buildings_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data exploration using filter_building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (df, 'town', 'block', 'street_name'); case-sensitve \n",
    "filter_building(full_cleaned, 'KALLANG/WHAMPOA', '28', 'JLN BAHAGIA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eg of a building that was scheduled for en-bloc hence last transaction date are in 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_building(full_cleaned, 'ANG MO KIO', '309', 'ANG MO KIO AVE 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to select the area 'ANG MO KIO', '309', 'ANG MO KIO AVE 1'\n",
    "selected_area = full_cleaned.loc[(full_cleaned['town'] == 'ANG MO KIO') &\n",
    "                                 (full_cleaned['block'] == '309') &\n",
    "                                 (full_cleaned['street_name'] == 'ANG MO KIO AVE 1')]\n",
    "\n",
    "# Plot a histogram of the 'month' column in the selected area\n",
    "selected_area['month'].hist(bins=12, edgecolor='black')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Months in ANG MO KIO, 309, ANG MO KIO AVE 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#here i found 'MULTI-GENERATION', 'MULTI GENERATION' exits, so all changed to 'MULTI GENERATION'\n",
    "full_cleaned['flat_type'] = full_cleaned['flat_type'].replace('MULTI-GENERATION', 'MULTI GENERATION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_model_order_by_average_prices = full_cleaned.groupby('flat_model')['resale_price'].mean().reset_index().sort_values(by = 'resale_price', ascending=True)\n",
    "flat_type_order_by_average_prices = full_cleaned.groupby('flat_type')['resale_price'].mean().reset_index().sort_values(by = 'resale_price', ascending=True)\n",
    "town_order_by_average_prices = full_cleaned.groupby('town')['resale_price'].mean().reset_index().sort_values(by = 'resale_price', ascending=True)\n",
    "mapping_town = {town: idx + 1 for idx, town in enumerate(town_order_by_average_prices['town'])}\n",
    "mapping_flat_model = {flat_model: idx + 1 for idx, flat_model in enumerate(flat_model_order_by_average_prices['flat_model'])}\n",
    "mapping_flat_type = {flat_type: idx + 1 for idx, flat_type in enumerate(flat_type_order_by_average_prices['flat_type'])}\n",
    "\n",
    "full_cleaned['flat_model_encoded'] = full_cleaned['flat_model'].map(mapping_flat_model)\n",
    "full_cleaned['flat_type_encoded'] = full_cleaned['flat_type'].map(mapping_flat_type)\n",
    "full_cleaned['town_encoded'] = full_cleaned['town'].map(mapping_town)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Street Name Encoding \n",
    "classify as region \n",
    "such as central, east, south  to reduce dimension\n",
    "reference：https://en.wikipedia.org/wiki/\n",
    "(i search for each town's wikipedia page and add them to different regions)\n",
    "\n",
    "CENTRAL: 'TOA PAYOH', 'QUEENSTOWN', 'MARINE PARADE', 'KALLANG/WHAMPOA', 'GEYLANG','CENTRAL AREA', 'BISHAN' ,'BUKIT TIMAH','BUKIT MERAH',\n",
    "EAST:'TAMPINES','PASIR RIS', 'BEDOK', \n",
    "NORTH: 'YISHUN', 'LIM CHU KANG', 'WOODLANDS''SEMBAWANG',  \n",
    "NORTHEAST: 'SERANGOON', 'SENGKANG','PUNGGOL', 'HOUGANG','ANG MO KIO', '\n",
    "WEST:'JURONG WEST', 'JURONG EAST', 'CLEMENTI','CHOA CHU KANG', 'BUKIT PANJANG', 'BUKIT BATOK', \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned['town'].unique()\n",
    "\n",
    "\n",
    "town_to_region = {\n",
    "    # Central Region\n",
    "    'TOA PAYOH': 'Central',\n",
    "    'QUEENSTOWN': 'Central',\n",
    "    'MARINE PARADE': 'Central',\n",
    "    'KALLANG/WHAMPOA': 'Central',\n",
    "    'GEYLANG': 'Central',\n",
    "    'CENTRAL AREA': 'Central',\n",
    "    'BISHAN': 'Central',\n",
    "    'BUKIT TIMAH': 'Central',\n",
    "    'BUKIT MERAH': 'Central',\n",
    "\n",
    "    # East Region\n",
    "    'TAMPINES': 'East',\n",
    "    'PASIR RIS': 'East',\n",
    "    'BEDOK': 'East',\n",
    "\n",
    "    # North Region\n",
    "    'YISHUN': 'North',\n",
    "    'LIM CHU KANG': 'North',\n",
    "    'WOODLANDS': 'North',\n",
    "    'SEMBAWANG': 'North',\n",
    "\n",
    "    # Northeast Region\n",
    "    'SERANGOON': 'Northeast',\n",
    "    'SENGKANG': 'Northeast',\n",
    "    'PUNGGOL': 'Northeast',\n",
    "    'HOUGANG': 'Northeast',\n",
    "    'ANG MO KIO': 'Northeast',\n",
    "\n",
    "    # West Region\n",
    "    'JURONG WEST': 'West',\n",
    "    'JURONG EAST': 'West',\n",
    "    'CLEMENTI': 'West',\n",
    "    'CHOA CHU KANG': 'West',\n",
    "    'BUKIT PANJANG': 'West',\n",
    "    'BUKIT BATOK': 'West'\n",
    "}\n",
    "\n",
    "# Map the town to its region and create a new column\n",
    "full_cleaned['region'] = full_cleaned['town'].map(town_to_region)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
